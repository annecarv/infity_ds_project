# An√°lise de Dados - Walmart

Objetivo: Realizar a an√°lise de um conjunto de dados de compras do Walmart, focando no comportamento de compra dos clientes com base em diferentes atributos, como g√™nero, categoria de produto, cidade, estado civil e faixa et√°ria. 

####  Objetivo

Gerar insights e visualizar as tend√™ncias desses dados de maneira eficiente. Tra√ßando um perfil do cliente e suas tendencias na hora da compra.

#### Dataset Utilizado

 - [Kaggle - Walmart Dataset](https://www.kaggle.com/datasets/devarajv88/walmart-sales-dataset)


#### Bibliotecas Utilizadas


- ``pandas: Para manipula√ß√£o e an√°lise de dados ``
- ``matplotlib: Para cria√ß√£o de gr√°ficos``
- ``numpy: Para computa√ß√£o num√©rica``
- ``seaborn: Para visualiza√ß√£o de dados baseada em matplotlib``
- ``xgboost: Para modelos de gradiente boosting``
- ``sklearn: Para machine learning, incluindo modelos, m√©tricas e pr√©-processamento``
- ``copy: M√≥dulo para manipula√ß√£o de objetos em Python``


#### Descri√ß√£o das Vari√°veis


| Vari√°vel          | Descri√ß√£o                                                        |
| ----------------- | ---------------------------------------------------------------- |
| User_ID           | Identifica√ß√£o do usu√°rio.                                         |
| Product_ID        | Identifica√ß√£o do produto.                                         |
| Gender            | G√™nero do usu√°rio. |
| Age               | Faixa et√°ria do usu√°rio.                                          |
| Occupation        | Ocupa√ß√£o do usu√°rio representada por um c√≥digo num√©rico.         |
| City_Category     | Categoria da cidade (A, B, ou C).                                 |
| Stay_In_Current_City_Years | Quantos anos o usu√°rio est√° na cidade atual (representado como 1, 2, 3, ou 4+). |
| Marital_Status    | Estado civil.          |
| Product_Category  | Categoria do produto.                                             |
| Purchase          | Valor da compra.



##### Tipos das Vari√°veis


| Vari√°vel          | Tipo                                                        |
| ----------------- | ---------------------------------------------------------------- |
|     Occupation       |          Inteiro - Categ√≥rica - Quantitativa (representa categorias ou grupos de ocupa√ß√£o, mas √© tratado como num√©rico)          |
|     Marital_Status   |          Inteiro  - Categ√≥rica  - Quantitativa (tamb√©m representa categorias, mas √© num√©rico)          |
|     Product_Category |          Inteiro  - Categ√≥rica - Quantitativa (representa categorias de produtos)         |
|     Purchase         |          Inteiro - Cardinal - Quantitativa (representa o valor da compra)         |
 |     Product_ID         |    Categ√≥rica - Nominal - Qualitativa (identificadores de produtos)   |
 |     Gender         |    Categ√≥rica - Nominal - Qualitativa (representa duas categorias: 'Male' e 'Female')   |
 |     User_ID         |    Categ√≥rica - Nominal - Qualitativa (representa categorias de usu√°rios)   |
 |     Age         |    Categ√≥rica - Ordinal - Qualitativa (faixas et√°rias)   |
 |     City_Category         |    Categ√≥rica - Nominal - Qualitativa (representa categorias de cidade)   |
 |     Stay_In_Current_City_Years         |    Categ√≥rica - Ordinal - Qualitativa (representa a dura√ß√£o da estadia em anos como categoria)   |

### Fases da An√°lise

##### 1. Limpeza e Agrupamento dos Dados

Identificar e corrigir problemas nos dados brutos que podem comprometer a precis√£o da an√°lise, verificando se h√° dados nulos/ausentes, discrepantes(outliers) ou inconsistentes. Nessa fase agrupando os dados por vari√°veis como estado civil, cidade e g√™nero, permitindo uma vis√£o geral da distribui√ß√£o dos clientes e suas compras. Gr√°ficos de barras s√£o gerados para ilustrar a quantidade e porcentagem de compras para cada grupo, ajudando a identificar padr√µes no comportamento de compra com base nessas caracter√≠sticas demogr√°ficas.

##### 2. Identifica√ß√£o de Outliers

Uma fase importantissima na prepara√ß√£o dos dados envolve a identifica√ß√£o de outliers no valor das compras. Isso √© feito usando a m√©trica do Intervalo Interquartil (IQR), que ajuda a identificar compras muito abaixo ou acima da m√©dia. Essa etapa √© importante para garantir que esses valores  n√£o distor√ßam a an√°lise e as previs√µes subsequentes.

##### 3. Agrupamentos e Percentuais

Essa etapa tem como objetivo entender a distribui√ß√£o dos dados em diferentes categorias e calcular estat√≠sticas para cada grupo. Isso ajuda a identificar padr√µes relevantes e gerar insights  sobre o comportamento dos clientes, produtos e compras.


##### 4. Gera√ß√£o de Gr√°ficos

Nessa etapa, convertemos os n√∫meros e percentuais calculados em representa√ß√µes visuais, facilitando a identifica√ß√£o de padr√µes.

##### 5. Prepara√ß√£o dos Dados para Machine Learning

Ap√≥s a an√°lise explorat√≥ria inicial, os dados s√£o preparados para modelos de machine learning. Que envolve mais uma fase de limpeza e transforma√ß√£o dos dados, com o objetivo de torna-los dados mais adequados para o modelo. S√£o aplicadas transforma√ß√µes de dados, como:

- Codifica√ß√£o de Vari√°veis Categ√≥ricas: Vari√°veis como Gender, City_Category e Age s√£o transformadas em formatos num√©ricos utilizando Label Encoding para que os modelos de machine learning possam process√°-las.

- Normaliza√ß√£o/Padroniza√ß√£o: Os valores das vari√°veis num√©ricas, como Purchase, podem ser normalizados ou padronizados, para melhorar a performance dos modelos de Machine Learning.

- Divis√£o dos Dados: Os dados s√£o ent√£o divididos em conjuntos de treino e teste. O conjunto de treino √© usado para ajustar o modelo, enquanto o conjunto de teste √© mantido separado para avaliar a capacidade do modelo de fazer previs√µes sobre dados n√£o vistos. Dividimos 25% para teste e 75% para treino.

##### 6. Sele√ß√£o e Treinamento de Modelos de Machine Learning

Nesta fase, diferentes algoritmos de machine learning s√£o aplicados, como por exemplo:

- ###### Regress√£o Linear (LinearRegression)

A Regress√£o Linear √© um modelo estat√≠stico que tenta prever o valor de uma vari√°vel dependente (target) com base em uma ou mais vari√°veis independentes (features) usando uma rela√ß√£o linear.
O modelo foi treinado com os dados de treino (X_treino, y_treino) e as previs√µes foram feitas sobre os dados de teste (y_pred). A acur√°cia √© avaliada com o m√©todo score() que retorna o coeficiente de determina√ß√£o ùëÖ¬≤

- ###### Classificador SGD (SGDClassifier)

O SGDClassifier √© um modelo que utiliza o m√©todo de Gradiente Descendente Estoc√°stico para otimiza√ß√£o. √â √∫til para problemas de classifica√ß√£o com grandes conjuntos de dados.
O modelo √© treinado em mini-lotes (batch) de dados, onde a cada itera√ß√£o ele atualiza os pesos de forma incremental. A acur√°cia √© avaliada com accuracy_score.

- ###### Regress√£o Log√≠stica (LogisticRegression)

A Regress√£o Log√≠stica √© um modelo de classifica√ß√£o que usa uma fun√ß√£o log√≠stica para modelar a probabilidade de uma classe ou evento, como um r√≥tulo bin√°rio (por exemplo, "sim" ou "n√£o").
Uso no c√≥digo: O modelo √© treinado com X_treino e y_treino, e as previs√µes podem ser geradas com o m√©todo predict().

- ###### √Årvore de Decis√£o (DecisionTreeRegressor)

Este modelo cria uma estrutura de √°rvore para prever valores, onde cada n√≥ representa uma pergunta sobre uma feature, e as folhas representam a previs√£o final.
O modelo √© treinado e avaliado da mesma forma que os anteriores, usando X_treino e y_treino.

- ###### Regress√£o Ridge (Ridge)

A Regress√£o Ridge √© uma t√©cnica de regulariza√ß√£o que adiciona um termo de penaliza√ß√£o √† fun√ß√£o de custo da regress√£o linear, ajudando a evitar overfitting.
O modelo √© treinado com X_treino e y_treino, e a acur√°cia √© avaliada usando score().

- ###### Random Forest (RandomForestRegressor)

O Random Forest √© um modelo de ensemble que cria v√°rias √°rvores de decis√£o durante o treinamento e combina suas previs√µes. Ele √© robusto contra overfitting e fornece boas previs√µes em muitos cen√°rios.
O modelo √© treinado e avaliado da mesma forma que os anteriores.

- ###### Regress√£o Lasso (Lasso)

A Regress√£o Lasso tamb√©m √© uma t√©cnica de regulariza√ß√£o que penaliza a soma dos valores absolutos dos coeficientes. Ela pode zerar alguns coeficientes, o que ajuda na sele√ß√£o de caracter√≠sticas.
O modelo √© treinado e avaliado da mesma forma que os anteriores.

- ###### Gradient Boosting (GradientBoostingRegressor)

O Gradient Boosting √© um modelo de ensemble que combina v√°rias √°rvores de decis√£o de forma sequencial, onde cada nova √°rvore corrige os erros da √°rvore anterior. √â um modelo muito eficaz para problemas de regress√£o e classifica√ß√£o.
O modelo √© treinado com os dados de treino e avaliado com score() nos dados de teste.



##### Avalia√ß√£o dos Modelos

- ###### Classifica√ß√£o

Objetivo:  Prever categorias discretas. √â uma tarefa de aprendizado supervisionado, na qual o objetivo √© prever uma categoria(r√≥tulo discreto) para novas observa√ß√µes com base em dados de treinamento rotulados.

Sa√≠da:  Resultados em forma de r√≥tulos (ex: "sim" ou "n√£o"). Um exemplo comum √© o reconhecimento de emails como "spam" ou "n√£o spam".

###### Modelos de Machine Learning para Classifica√ß√£o:

- Regress√£o Log√≠stica
- √Årvores de Decis√£o
- Support Vector Machines (SVM)
- Redes Neurais
- Random Forest

###### M√©tricas de Avalia√ß√£o:

- Acur√°cia
- Precis√£o
- Recall
- F1 Score
- Matriz de Confus√£o

- ###### Regress√£o

Objetivo: Prever valores cont√≠nuos. √â uma tarefa de aprendizado supervisionado, na qual o objetivo √© prever um valor cont√≠nuo para novas observa√ß√µes com base em dados de treinamento rotulados.

Sa√≠da: Resultados em forma de n√∫meros reais, um exemplo √© prever o pre√ßo de uma casa com base em suas caracter√≠sticas (tamanho, localiza√ß√£o, n√∫mero de quartos).

###### Modelos Comuns:

- Regress√£o Linear
- Regress√£o Polinomial
- √Årvores de Decis√£o para Regress√£o
- Random Forest para Regress√£o
- Gradient Boosting

###### M√©tricas de Avalia√ß√£o:

- Mean Absolute Error (MAE)
- Mean Squared Error (MSE)
- R¬≤ Score
- Root Mean Squared Error (RMSE)
- Resumo das Diferen√ßas

##### An√°lise dos Resultados dos Modelos de Machine Learning


- **√Årvore de Decis√£o**

MSE: 0.2212 (Baixo)
MAE: 0.3445 (Baixo)
R¬≤ Score: 0.6413 (Bom)
Teve um bom desempenho, com baixos valores de MSE e MAE e um R¬≤ razoavelmente alto. Ele pode captar padr√µes, mas pode ser superado por modelos mais robustos.

- **Regress√£o Linear**

MSE: 0.2212 (Igual ao modelo de √°rvore de decis√£o)
MAE: 0.3445 (Igual ao modelo de √°rvore de decis√£o)
R¬≤ Score: 0.6413 (Igual ao modelo de √°rvore de decis√£o)
Teve o mesmo desempenho que a √°rvore de decis√£o em todas as m√©tricas. Isso sugere que ambas as abordagens est√£o captando os mesmos padr√µes, por√©m a simplicidade da regress√£o linear pode ser uma vantagem.

- **Gradient Boosting**

MSE: 0.2293 (Levemente maior)
MAE: 0.3663 (Levemente maior)
R¬≤ Score: 0.6282 (Levemente menor)
O modelo de Gradient Boosting tem m√©tricas um pouco piores do que os modelos de √°rvore de decis√£o e regress√£o linear, mas ainda √© competitivo. Isso sugere que, nesse conjunto de dados, o modelo pode n√£o ter captado tantos padr√µes adicionais como esperado.

- **Random Forest**

MSE: 0.2184 (Melhor MSE)
MAE: 0.3436 (Melhor MAE)
R¬≤ Score: 0.6458 (Melhor R¬≤)
Teve o melhor desempenho geral entre os modelos avaliados, com os menores valores de erro (MSE e MAE) e o maior valor de R¬≤. Ele consegue captar a complexidade dos dados com um bom n√≠vel de generaliza√ß√£o.

- **Regress√£o Ridge**

MSE: 0.5043 (Alto)
MAE: 0.5426 (Alto)
R¬≤ Score: 0.1822 (Fraco)
Desempenho ruim, os erros s√£o altos e o R¬≤ √© muito baixo, sugerindo que o modelo n√£o est√° captando bem os padr√µes dos dados.

- **Regress√£o Lasso**

MSE: 0.5248 (Maior)
MAE: 0.5612 (Maior)
R¬≤ Score: 0.1489 (Fraco)
O pior desempenho entre os modelos avaliados, com os maiores erros e o menor R¬≤. Ou seja, sse modelo n√£o est√° captando bem a variabilidade dos dados.


**Melhor Modelo:** O Random Forest teve o melhor desempenho com os menores erros (MSE e MAE) e o maior R¬≤, se mostrando que o mais eficaz para o conjunto de dados.
**Piores Modelos:** Tanto a Regress√£o Ridge quanto a Regress√£o Lasso tiveram desempenhos fracos, sugerindo que elas n√£o s√£o adequadas para este problema.
**Modelos Satisfat√≥rios:** √Årvore de Decis√£o e Regress√£o Linear tiveram desempenhos praticamente iguais e razoavelmente bons, embora n√£o t√£o eficazes quanto o Random Forest.


##### Conclus√£o

Por meio deste projeto, podemos experienciar como √© uma situa√ß√£o real onde a an√°lise e ci√™ncia de dados √© essencial para a tomada de decis√µes. Vimos desde o in√≠cio, que come√ßa com o tratamento dos dados, sendo esta a fase mais extensa e importante, at√© o treinamento e avalia√ß√£o dos modelos de Machine Learning.
